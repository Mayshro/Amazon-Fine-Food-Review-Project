{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1HwzJoXrKYntaVFhxMz4NcDaMzNyFmMT8",
      "authorship_tag": "ABX9TyP9Ovy0dJKNqDrbYGsVLGnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayshro/Amazon-Fine-Food-Review-Project/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading The Dataset"
      ],
      "metadata": {
        "id": "8xd7xIb5C0Ov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tTx8TEIzN9p"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data."
      ],
      "metadata": {
        "id": "ikS2IzSQ0niG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Reviews.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "MCNTMbQ501Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis\n",
        "#Remove Duplicates, missing values and will focus on score and text colums to predit reviews. Removing all scores that are equal to 3. adding new colum \"positivity\" where score above 3 is 1 and is positively rated otherwise it'ii be 0, indicating it asnegatively rated.**bold text**"
      ],
      "metadata": {
        "id": "hmxXsdTzC-2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(x):\n",
        "    if x < 3:\n",
        "        return 0\n",
        "    return 1"
      ],
      "metadata": {
        "id": "ZF9RTSn6Cs9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data = data.copy()\n",
        "actualScore = filtered_data['Score']\n",
        "positiveNegative = actualScore.map(partition) \n",
        "filtered_data['Score'] = positiveNegative\n",
        "print(\"Number of data points in our data\", filtered_data.shape)\n",
        "filtered_data.head(3)"
      ],
      "metadata": {
        "id": "h6ZUjkUtcneG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deduplication of entries"
      ],
      "metadata": {
        "id": "JZPuciXTEL97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = {\"UserId\", \"ProfileName\", \"Time\", \"Text\"}\n",
        "data = filtered_data.drop_duplicates(subset=subset, keep=\"first\")\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "lIBhJPAaDutz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cgecking to see how much % of data still remains"
      ],
      "metadata": {
        "id": "ytgK8QvMFuaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking to see how much % of data still remains\n",
        "(data['Id'].size)/(filtered_data['Id'].size)*100"
      ],
      "metadata": {
        "id": "lEEmzX9Zd5yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['HelpfulnessNumerator'] > data['HelpfulnessDenominator']]"
      ],
      "metadata": {
        "id": "te55v6KNEQSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['HelpfulnessNumerator'] <= data['HelpfulnessDenominator']]\n",
        "data.reset_index(drop = True, inplace=True)\n",
        "print(data.shape)\n",
        "data.head(3)"
      ],
      "metadata": {
        "id": "VTrOIoaVF2Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing -\n",
        "Removing html tags, punctuations or special characters.\n",
        "Check if word has english letters and is not alpha numeric\n",
        "Check the word length greater than 2(as it was researched that there is no adjective in 2-letters)\n",
        "Convert the words to lowercase\n",
        "Remove Stopwords\n",
        "Finally, Snowball Stemming the word\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "JLNno4GdH1Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding sentences containing HTML tags"
      ],
      "metadata": {
        "id": "Pl9CLT7_MAjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set of stopwords\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "#initialising the snowball stemmer\n",
        "sno = nltk.stem.SnowballStemmer('english')                      \n",
        "\n",
        "\n",
        "#function to clean the word of any html-tags\n",
        "def cleanhtml(sentence): \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', sentence)\n",
        "    return cleantext\n",
        "\n",
        "\n",
        "\n",
        "#function to clean the word of any punctuation or special characters\n",
        "def cleanpunc(sentence): \n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return  cleaned\n",
        "\n",
        "\n",
        "#function to text summarization\n",
        "def final_sentence(text):\n",
        "    \n",
        "    text = text.split()\n",
        "    text = [cleanhtml(x) for x in text]\n",
        "    text = [cleanpunc(x) for x in text]\n",
        "    \n",
        "    def test(word):\n",
        "        if word.isalpha() and len(word) > 2 and word.lower() not in stop:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    \n",
        "    text = [x for x in text if test(x)]\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "yNn0jLIdMHHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use n-grams to convert text into numeric forms as it consider a pair of consequent words."
      ],
      "metadata": {
        "id": "KX8Lbtr7QR4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['CleanedText'] = data['Text'].apply(final_sentence)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "NwcjCnSfQd4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Text_Into_Vector(model,data):\n",
        "    model_vect = model(ngram_range=(1,2)) #in scikit-learn\n",
        "    final_array = model_vect.fit_transform(data.values)\n",
        "\n",
        "    print(\"the type of count vectorizer \",type(final_array))\n",
        "    print(\"the shape of out text BOW vectorizer \",final_array.get_shape())\n",
        "    print(\"the number of unique words including both unigrams and bigrams \", final_array.get_shape()[1])\n",
        "    \n",
        "    return model_vect, final_array"
      ],
      "metadata": {
        "id": "FgWj94DDg4us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def Split_data(x_vec, y_vec):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(x_vec, y_vec, test_size=.33, random_state=0)\n",
        "    X_tr, X_cv, Y_tr, Y_cv = train_test_split(X_train, Y_train, test_size=.33, random_state=0)\n",
        "    return X_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train\n"
      ],
      "metadata": {
        "id": "qKmMmE_Qg9EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Data\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "def Normalization(train, cv, test):\n",
        "    train=preprocessing.normalize(train)\n",
        "    cv=preprocessing.normalize(cv)\n",
        "    test=preprocessing.normalize(test)\n",
        "\n",
        "    print(\"Train Data Size \",train.get_shape())\n",
        "    print(\"CV Data Size: \",cv.shape)\n",
        "    print(\"Test Data Size: \",test.shape)\n",
        "    \n",
        "    return train, cv, test"
      ],
      "metadata": {
        "id": "LJRTzWDUg9Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pylab as pyplt\n",
        "\n",
        "def Multinomial_NB(X_train,X_cv,Y_train,Y_cv):\n",
        "    #############################################################################\n",
        "    best_alpha=0\n",
        "    max_roc_auc=-1\n",
        "    pred_cv = []\n",
        "    pred_train = []\n",
        "    alpha=[10000,5000,1000,500,100,50,10,5,1,0.5,0.1,0.05,0.01,0.005,0.001,0.0005,0.0001,0.00005,0.00001]\n",
        "    #############################################################################\n",
        "\n",
        "    for i in alpha:\n",
        "        mulbnb = MultinomialNB(alpha=i)\n",
        "        mulbnb.fit(X_train,Y_train)\n",
        "        probs = mulbnb.predict_proba(X_cv)[:,1]     \n",
        "        prob = mulbnb.predict_proba(X_train)[:,1]\n",
        "        #############################################################################\n",
        "\n",
        "        auc_score_cv = roc_auc_score(Y_cv,probs)            #auc roc for cv\n",
        "        auc_score_train = roc_auc_score(Y_train,prob)       #auc roc for train\n",
        "        #############################################################################\n",
        "\n",
        "        print(i,\" ------> \",auc_score_cv)\n",
        "        #############################################################################\n",
        "\n",
        "        pred_cv.append(auc_score_cv)\n",
        "        pred_train.append(auc_score_train)\n",
        "        #############################################################################\n",
        "\n",
        "        if(max_roc_auc<auc_score_cv):\n",
        "            max_roc_auc=auc_score_cv\n",
        "            best_alpha=i\n",
        "\n",
        "    print(\"*\"*100)\n",
        "    print(f\"\\n Best alpha Value {best_alpha} with highest roc_auc Score is {max_roc_auc}\")\n",
        "    print(\"*\"*100)\n",
        "    #############################################################################\n",
        "\n",
        "    sns.set_style(\"darkgrid\")\n",
        "    plt.xscale('log')\n",
        "    plt.plot(alpha, pred_cv,'r-', label = 'CV Data')\n",
        "    plt.plot(alpha,pred_train,'g-', label ='Train Data')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(r'Auc Score v/s $\\alpha$')\n",
        "    plt.xlabel(r\"alpha values\",fontsize=12)\n",
        "    plt.ylabel(\"roc_auc\",fontsize=12)\n",
        "    plt.show()\n",
        "    print(\"*\"*100)\n",
        "    #############################################################################\n",
        "\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y_cv,probs)\n",
        "    # plot no skill\n",
        "    pyplt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    # plot the roc curve for the model\n",
        "    pyplt.plot(fpr, tpr, marker='.')\n",
        "    pyplt.title(\"Line Plot of ROC Curve on Train Data\")\n",
        "    pyplt.ylabel('True Positive Rate')\n",
        "    pyplt.xlabel('False Positive Rate')\n",
        "    pyplt.show()\n",
        "    print(\"*\"*100)\n",
        "    \n",
        "    #############################################################################\n",
        "    return best_alpha"
      ],
      "metadata": {
        "id": "jLwpp1nPg91F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def Testing_model(X_train,Y_train,X_test,Y_test,best_alpha):\n",
        "    \n",
        "    #############################################################################\n",
        "    bnb = MultinomialNB(alpha = best_alpha, fit_prior=True, class_prior=None)\n",
        "    bnb.fit(X_train,Y_train)\n",
        "    probs = bnb.predict_proba(X_test)[:,1]            # keep probabilities for the positive outcome only\n",
        "\n",
        "    #############################################################################\n",
        "    roc_auc = roc_auc_score(Y_test,probs)\n",
        "    print(\"AUC Score\",roc_auc)\n",
        "    print(\"*\"*70)\n",
        "    #############################################################################'\n",
        "\n",
        "    # calculate roc curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test,probs)\n",
        "    # plot no skill\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    # plot the roc curve for the model\n",
        "    plt.plot(fpr, tpr, marker='.')\n",
        "    plt.title(\"Line Plot of ROC Curve on Test Data\")\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')    \n",
        "    plt.show()\n",
        "\n",
        "    #############################################################################\n",
        "    prediction=bnb.predict(X_test)\n",
        "    #skplt.plot_confusion_matrix(Y_test,prediction)\n",
        "    #############################################################################\n",
        "\n",
        "    print(\"macro f1 score for data :\",metrics.f1_score(Y_test, prediction, average = 'macro'))\n",
        "    print(\"micro f1 score for data:\",metrics.f1_score(Y_test, prediction, average = 'micro'))\n",
        "    print(\"hamming loss for data:\",metrics.hamming_loss(Y_test,prediction))\n",
        "    print(\"*\"*70)\n",
        "    print(\"Precision recall report for data:\\n\",metrics.classification_report(Y_test, prediction))\n",
        "    print(\"*\"*70)\n",
        "    \n",
        "    return bnb,roc_auc"
      ],
      "metadata": {
        "id": "jThrDTZ3P8vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing:As we have finished processing the review text , Itâ€™s time to split our data into a training and a test set using train_test_split from Scikit-learn. We will use 30% of the dataset for testing and remaining 70% is for training"
      ],
      "metadata": {
        "id": "ytvpqeQ0Swz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Important_features(model, classifier):\n",
        "    neg = classifier.feature_log_prob_[0].argsort()\n",
        "    pos = classifier.feature_log_prob_[1].argsort()\n",
        "    top_pos_words = np.take(model.get_feature_names(),pos)\n",
        "    top_neg_words = np.take(model.get_feature_names(),neg)\n",
        "    imp_df = pd.DataFrame(columns = ['Pos_Words','Pos_Importance','Neg_Words','Neg_Importance'])\n",
        "    imp_df['Pos_Words'] = top_pos_words[::-1]\n",
        "    imp_df['Pos_Importance'] = np.take(classifier.feature_log_prob_[1],pos)[::-1]\n",
        "    imp_df['Neg_Words'] = top_neg_words[::-1]\n",
        "    imp_df['Neg_Importance'] = np.take(classifier.feature_log_prob_[0],neg)[::-1]\n",
        "    return imp_df"
      ],
      "metadata": {
        "id": "2OcXbRgySvkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Individual_Prediction(model, classifier, review):\n",
        "    review = final_sentence(review)\n",
        "    review_vec = model.transform([review])\n",
        "    review_vec = preprocessing.normalize(review_vec)\n",
        "    pred = classifier.predict(review_vec)\n",
        "\n",
        "    return \"positive review\" if pred[0] == 1 else \"negative review\"\n"
      ],
      "metadata": {
        "id": "k4W7MCv7Ture"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "BOW, X = Text_Into_Vector(CountVectorizer,data['CleanedText'])\n"
      ],
      "metadata": {
        "id": "4ncI2t94VT3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOW.get_params()"
      ],
      "metadata": {
        "id": "bJCphKueinJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into train, cross validate and test \n",
        "\n",
        "X_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train = Split_data(X, data['Score'])\n"
      ],
      "metadata": {
        "id": "4ZKqjYOZjAoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_test, Y_test', X_test.shape, Y_test.shape)\n",
        "print('X_tr, Y_tr', X_tr.shape, Y_tr.shape)\n",
        "print('X_cv, Y_cv', X_cv.shape, Y_cv.shape)\n",
        "print('X_Train, Y_Train', X_train.shape, Y_train.shape)"
      ],
      "metadata": {
        "id": "6KP2DXOpjLFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "X_tr, X_cv, X_test = Normalization(X_tr, X_cv, X_test)"
      ],
      "metadata": {
        "id": "zGKK5Ibfjdge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=46)\n",
        "X_tr,Y_tr =smote.fit_resample(X_tr,Y_tr)"
      ],
      "metadata": {
        "id": "H85MJ0xxlRnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha_bow = Multinomial_NB(X_tr,X_cv,Y_tr,Y_cv)"
      ],
      "metadata": {
        "id": "ELcLYYpTjdXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing NB Model\n",
        "\n",
        "NB_bow, roc_auc_bow = Testing_model(X_tr,Y_tr,X_test,Y_test,best_alpha_bow)\n"
      ],
      "metadata": {
        "id": "hezz4yuwjdP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "TfIdf, X = Text_Into_Vector(TfidfVectorizer,data['CleanedText'])\n"
      ],
      "metadata": {
        "id": "Y1r3LsyQjdCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train = Split_data(X, data['Score'])\n",
        "print('X_test, Y_test', X_test.shape, Y_test.shape)\n",
        "print('X_tr, Y_tr', X_tr.shape, Y_tr.shape)\n",
        "print('X_cv, Y_cv', X_cv.shape, Y_cv.shape)\n",
        "print('X_Train, Y_Train', X_train.shape, Y_train.shape)"
      ],
      "metadata": {
        "id": "pJBQMW7MmgAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Data\n",
        "\n",
        "X_tr, X_cv, X_test = Normalization(X_tr, X_cv, X_test)"
      ],
      "metadata": {
        "id": "JYzif5lrmw_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=45)\n",
        "X_tr,Y_tr = smote.fit_resample(X_tr,Y_tr)"
      ],
      "metadata": {
        "id": "025VcjFamxId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training NB model\n",
        "\n",
        "best_alpha_idf = Multinomial_NB(X_tr,X_cv,Y_tr,Y_cv)"
      ],
      "metadata": {
        "id": "5mTbwmC_mxOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing NB Model\n",
        "\n",
        "NB_tfidf, roc_auc_idf = Testing_model(X_tr,Y_tr,X_test,Y_test,best_alpha_idf)\n",
        " "
      ],
      "metadata": {
        "id": "A5GTkoiznaIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\" The food was really bad i did not like it\"\"\"\n",
        "print(\"Prediction using BOW:\", Individual_Prediction(BOW, NB_bow, review))\n",
        "print(\"Prediction using TF-Idf:\", Individual_Prediction(TfIdf, NB_tfidf, review))\n"
      ],
      "metadata": {
        "id": "JHp_mxGdNEQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pra-9Pb8OKfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}